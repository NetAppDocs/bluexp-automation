---
sidebar: sidebar
permalink: cm/wf_aws_ontap_create_vol_nfs.html
keywords: cloud, manager, rest, api, aggregate, svm, virtual, private, cloud
summary: 'You can use this workflow to create a volume accessed through NFS.'
---

= Create a volume using NFS

:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/

[.lead]
You can use this workflow to create a volume accessed through the NFS protocol.


[NOTE]
If the properties `aggregateName` and `maxNumOfDisksApprovedToAdd` are not provided on the REST API call, the response will fail with a suggested name for the aggregate and the number of disks needed to fulfill the request.

Choose the workflow to use based on the type of Cloud Volumes ONTAP deployment:

* <<Create a volume using NFS for single node, Single Node>>
* <<Create a volume using NFS for high availability pair, HA pair>>

== Create a volume using NFS for single node
You can use this workflow to create a volume using NFS for a single node system.

=== Step 1. Select a working environment

Perform the workflow link:wf_aws_cloud_get_wes.html#get-working-environments-for-single-node[Get working environments] and choose the `publicId` and the `svmName` values for the `workingEnvironmentId`  and the `svmName` parameters.  From the `capacityFeatures` field in the response, choose the value of `s3` for the `capacityTier` parameter. 

=== Step 2. Select an aggregate

Perform the workflow link:wf_aws_ontap_get_aggrs.html#get-aggregates-for-single-node[Get aggregates] and choose the `name` value of the aggregate for the `name` parameter. From the `providerVolumes` field in the response, you must also choose the value of `diskType` for the `providerVolumeType` parameter, the value of `iops` for the `iops` parameter, and the value of `throughput` for the `throughput` parameter.

[NOTE]
If aggregate name does not exist and the `createAggregateIfNotFound` query parameter is set `true`, the create volume request is allowed if the named aggregate is not found.

=== Step 3. Select a virtual private cloud

Perform the workflow link:wf_aws_cloud_md_get_vpcs.html#get-vpcs-for-single-node[Get virtual private clouds] and choose the `cidrBlock` value of the required VPC for the `ips` parameter or fill in the desired `exportPolicyInfo` value manually.

=== Step 4. Choose the size for the disk

Choose the size value for the `size:size` parameter. The `size:unit` must be one of the following: `TB`, `GB`, `MB`, `KB`, or `Byte`.


=== Step 5. Select the rules

Choose values for the `exportPolicyInfo->rules->ruleAccessControl` and `exportPolicyInfo->rules->superUser` parameters.

=== Step 6. Create a quote

Perform the workflow link:wf_aws_ontap_create_quote.html#create-quote-for-single-node[Create quote]. This is a recommended step but is not mandatory.

=== Step 7. Create a volume


You can issue the REST API call to create the volume.

.HTTP method and endpoint

This REST API call uses the following method and endpoint.


[cols="25,75"*,options="header"]
|===
|HTTP method
|Path
|POST
|/occm/api/vsa/volumes
|===

.Curl example: Create a volume

[source,curl]
curl --location "https://api.bluexp.netapp.com/occm/api/vsa/volumes?createAggregateIfNotFound=false" \
--request POST \
--header "Content-Type: application/json" \
--header "x-agent-id: <AGENT_ID>" \
--header "Authorization: Bearer <ACCESS_TOKEN>" \
--d @JSONinput

.Additional input parameters

The JSON input example includes the minimum list of parameters.

[cols="25,25, 25, 45"*,options="header"]
|===
|Parameter
|Type
|Required
|Description
|<SVM_NAME> `(svmName)` |Query |Yes |Identifies the SVM
|`workingEnvironmentId` <WORKING_ENV_ID> |Query |Yes |Identifies the working environment ID
|<AGGR_NAME> `(aggregateName)` |Query |Yes |Identifies the aggregate
| `providerVolumeType`  | Query |Yes | Specifies the provider volume type.
| `iops` | Query | Yes| Specifies the input/output operations per second.
| `throughput` | Query| Yes | Specifies the throughput.

   
|===


If aggregate name does not exist, you can set the `createAggregateIfNotFound` query parameter to `true` which allows the aggregate not-found condition.

.JSON input example

[source,json]
{ 
    "workingEnvironmentId": "VsaWorkingEnvironment-Z1bEUQE6", 
    "svmName": "svm_testcvosn", 
    "aggregateName": "aggr1", 
    "name": "mysql_data_volume", 
    "size": { 
        "size": "1", 
        "unit": "GB" 
    }, 
    "snapshotPolicyName": "default", 
    "exportPolicyInfo": { 
        "policyType": "custom", 
        "rules": [ 
            { 
                "index": 1, 
                "ruleAccessControl": "readwrite", 
                "ips": [ 
                    "10.20.0.0/16" 
                ], 
                "nfsVersion": [ 
                    "nfs3", 
                    "nfs4" 
                ], 
                "superUser": true 
            } 
        ] 
    }, 
    "enableThinProvisioning": true, 
    "enableCompression": true, 
    "enableDeduplication": true, 
    "maxNumOfDisksApprovedToAdd": 0, 
    "evCapacityApprovedToAdd": null, 
    "verifyNameUniqueness": true, 
    "providerVolumeType": "gp3", 
    "iops": 3000, 
    "throughput": 250, 
    "capacityTier": "S3", 
    "tieringPolicy": "auto", 
    "minimumCoolingDays": 31 
} 

 

.JSON output example

None


== Create a volume using NFS for high availability pair
You can use this workflow to create volume using NFS for an HA working environment.

=== Step 1. Select a working environment

Perform the workflow link:wf_aws_cloud_get_wes.html#get-working-environments-for-high-availability-pair[Get working environments] and choose the `publicId` and the `svmName` values for the `workingEnvironmentId`  and the `svmName` parameters. From the `capacityFeatures` field in the response, choose the value of `s3` for the `capacityTier` parameter. 


=== Step 2. Select an aggregate

Perform the workflow link:wf_aws_ontap_get_aggrs.html#get-aggregates-for-high-availability-pair[Get aggregates] and choose the `name` value of the aggregate for the `name` parameter.  From the `providerVolumes` field in the response, you must also choose the value of `diskType` for the `providerVolumeType` parameter, the value of `iops` for the `iops` parameter, and the value of `throughput` for the `throughput` parameter.

[NOTE]
If aggregate name does not exist and the `createAggregateIfNotFound` query parameter is set `true`, the create volume request is allowed if the named aggregate is not found.

=== Step 3. Select a virtual private cloud

Perform the workflow link:wf_aws_cloud_md_get_vpcs.html#get-vpcs-for-high-availability-pair[Get virtual private clouds] and choose the `cidrBlock` value of the required VPC for the `ips` parameter or fill in the desired `exportPolicyInfo` value manually.

=== Step 4. Choose the size for the disk

Choose the size value for the `size:size` parameter. The `size:unit` must be one of the following: `TB`, `GB`, `MB`, `KB`, or `Byte`.

=== Step 5. Select the rules

Choose values for the `exportPolicyInfo->rules->ruleAccessControl` and `exportPolicyInfo->rules->superUser`
parameters.

=== Step 6. Create a quote

Perform the workflow link:wf_aws_ontap_create_quote.html#create-quote-for-high-availability-pair[Create quote]. This is a recommended step but is not mandatory.

=== Step 7. Create a volume

You can issue the REST API call to create a volume.

.HTTP method and endpoint

This REST API call uses the following method and endpoint.


[cols="25,75"*,options="header"]
|===
|HTTP method
|Path
|POST
|/occm/api/aws/ha/volumes
|===

.Curl example: Create a volume

[source,curl]
curl --location "https://api.bluexp.netapp.com/occm/api/aws/ha/volumes?createAggregateIfNotFound=false" \
--request POST \
--header "Content-Type: application/json" \
--header "x-agent-id: <AGENT_ID>" \
--header "Authorization: Bearer <ACCESS_TOKEN>" \
--d @JSONinput

.Additional input parameters

The JSON input example includes the minimum list of parameters.

[cols="25,25, 25, 45"*,options="header"]
|===
|Parameter
|Type
|Required
|Description
|<SVM_NAME> `(svmName)` |Query |Yes |Identifies the SVM
|`workingEnvironmentId` <WORKING_ENV_ID> |Query |Yes |Identifies the working environment ID
|<AGGR_NAME> `(aggregateName)` |Query |Yes |Identifies the aggregate
| `providerVolumeType`  | Query |Yes | Specifies the provider volume type.
| `iops` | Query | Yes| Specifies the input/output operations per second.
| `throughput` | Query| Yes | Specifies the throughput.
|===


If aggregate name does not exist, you can set the `createAggregateIfNotFound` query parameter to `true` which allows the aggregate not-found condition.

.JSON input example

[source,json]
{ 
    "workingEnvironmentId": "VsaWorkingEnvironment-ogAu9i3S", 
    "svmName": "svm_testcvoha", 
    "aggregateName": "aggr1", 
    "name": "oracle_log_volume", 
    "size": { 
        "size": "1", 
        "unit": "GB" 
    }, 
    "snapshotPolicyName": "default", 
    "exportPolicyInfo": { 
        "policyType": "custom", 
        "rules": [ 
            { 
                "index": 1, 
                "ruleAccessControl": "readwrite", 
                "ips": [ 
                    "10.20.0.0/16" 
                ], 
                "nfsVersion": [ 
                    "nfs3", 
                    "nfs4" 
                ], 
                "superUser": true 
            } 
        ] 
    }, 
    "enableThinProvisioning": true, 
    "enableCompression": true, 
    "enableDeduplication": true, 
    "maxNumOfDisksApprovedToAdd": 0, 
    "evCapacityApprovedToAdd": null, 
    "verifyNameUniqueness": true, 
    "providerVolumeType": "gp3", 
    "iops": 3000, 
    "throughput": 250, 
    "capacityTier": "S3", 
    "tieringPolicy": "auto", 
    "minimumCoolingDays": 31 
} 

.JSON output example

None
